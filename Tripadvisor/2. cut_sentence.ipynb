{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將原始評論過濾掉外文,emoji,過多的英文並轉換出各分類次評等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from opencc import OpenCC\n",
    "import seaborn as sns\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_japenese(uchar):\n",
    "    if (uchar >= u'\\u30a0' and uchar <= u'\\u30ff') or (uchar >= u'\\u3040' and uchar <= u'\\u309f'):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def checkjapenese(sen):\n",
    "    e=0\n",
    "    c=0\n",
    "    for i in sen:\n",
    "        if is_japenese(i):\n",
    "            e+=1\n",
    "        if is_chinese(i):\n",
    "            c+=1\n",
    "    if c>0:\n",
    "        return(e/c>0.5)\n",
    "    else:\n",
    "        return(True)\n",
    "def is_alphabet(uchar):\n",
    "    if (uchar >= u'\\u0041' and uchar <= u'\\u005a') or (uchar >= u'\\u0061' and uchar <= u'\\u007a'):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def is_chinese(uchar):\n",
    "    if uchar >= u'\\u4e00' and uchar <= u'\\u9fa5':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def checkEng(sen):\n",
    "    e=0\n",
    "    c=0\n",
    "    for i in sen:\n",
    "        if is_alphabet(i):\n",
    "            e+=1\n",
    "        if is_chinese(i):\n",
    "            c+=1\n",
    "    if c>0:\n",
    "        return(e/c>0.5)\n",
    "    else:\n",
    "        return(True)\n",
    "\n",
    "\n",
    "cc = OpenCC('s2t')\n",
    "allLang=pd.read_csv('./crawler/TPE_GCP_allLang.csv',low_memory=False)\n",
    "allLang=allLang[(allLang['review'].apply(checkEng)==False)&(allLang.auto_translate==False)&(allLang['review'].apply(checkjapenese)==False)]\n",
    "\n",
    "allLang.total_dict=allLang.total_dict.apply(lambda x:eval(x))\n",
    "ch_list=[]\n",
    "for list_ in allLang['total_dict'].apply(lambda x:x.keys()):\n",
    "    for key in list_:\n",
    "        if key not in ch_list:\n",
    "            ch_list.append(key)\n",
    "ch_list=ch_list[:-4]\n",
    "en_list=['cp','place','service','comfort','clean','sleep']\n",
    "for en,ch in zip(en_list,ch_list):\n",
    "    allLang[f'is_{en}']=allLang['total_dict'].apply(lambda x:x.get(ch))\n",
    "    \n",
    "allLang=allLang.reset_index().rename(columns={'index':'old_index'})\n",
    "allLang.to_csv('original_review.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 情緒詞根據出現次數進行過濾後，並進行人工識別建立旅遊評論情感詞字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_list=[\"“\",\"”\",\"（\",\"）\",\"(\",\")\",\"【\",\"】\",\"：\",\":\",\";\",'\"',\"'\",\"/\",\"-\",\"～\",\"~\",\"⋯\",\".\",\"=\",'*',\"^\",\"#\",'_','▽','´',\"`\"]\n",
    "def extract_emojis(s): ##簡繁轉換,情緒符號\n",
    "    s=cc.convert(s)\n",
    "    s=s.replace('ㄧ','一')\n",
    "    for sym in sym_list:\n",
    "        s=s.replace(sym,\" \")\n",
    "    return ''.join(c for c in s if c not in emoji.UNICODE_EMOJI)\n",
    "## 進行斷詞\n",
    "ws = WS(\"./outsourced_data\")\n",
    "pos = POS(\"./outsourced_data\")\n",
    "original_review=pd.read_csv('original_review.csv')\n",
    "original_review=original_review[['old_index','review']]\n",
    "original_review.columns=['old_index','ori_review']\n",
    "original_review['ori_review']=original_review['ori_review'].apply(extract_emojis)\n",
    "original_review['token_ckip']=original_review['ori_review'].apply(lambda x:ws([x]))\n",
    "original_review['pos_ckip']=original_review['token_ckip'].apply(pos)\n",
    "original_review=original_review.reset_index(drop=True)\n",
    "def merge_pos(x):\n",
    "    pos_list=[]\n",
    "    for token ,pos in zip(x['token_ckip'][0],x['pos_ckip'][0]):\n",
    "        if pos=='WHITESPACE':\n",
    "            continue\n",
    "        pos_list.append((token,pos))\n",
    "    return(pos_list)\n",
    "original_review['merge_pos']=original_review.apply(merge_pos,axis=1)\n",
    "original_review.to_csv('token_pos_ckip.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根據中斷標點符號進行切割句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pos_ckip=pd.read_csv('token_pos_ckip.csv')##old_index,sentence,pos\n",
    "token_pos_ckip['merge_pos']=token_pos_ckip['merge_pos'].apply(eval)\n",
    "total_sentence=[]\n",
    "for old_index,merge_pos in zip(token_pos_ckip['old_index'],token_pos_ckip['merge_pos']):\n",
    "    wordString=''\n",
    "    sentence_list=[]\n",
    "    for i,word_pos in enumerate(merge_pos):\n",
    "        word,pos=word_pos\n",
    "        wordString+=word\n",
    "        sentence_list.append(word_pos)\n",
    "        if( pos in ['PERIODCATEGORY','ETCCATEGORY','EXCLAMATIONCATEGORY','QUESTIONCATEGORY','SEMICOLONCATEGORY']):\n",
    "            total_sentence.append([old_index,wordString[:-1],sentence_list[:-1]])\n",
    "            wordString=''\n",
    "    total_sentence.append([old_index,wordString,sentence_list])\n",
    "\n",
    "cut_sentence=pd.DataFrame(total_sentence,columns=['old_index','sentence','pos'])\n",
    "\n",
    "cut_sentence=cut_sentence[cut_sentence.sentence!='']\n",
    "\n",
    "cut_sentence.to_csv('By_sentence_pos.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
