{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加入LDA建立的2個新主題特徵\n",
    "* 餐廳飲食、環境設備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "By_sentence_pos=pd.read_csv('By_sentence_pos.csv')\n",
    "By_sentence_pos['pos']=By_sentence_pos['pos'].apply(lambda x:eval(x))\n",
    "By_sentence_pos['token_ckip']=By_sentence_pos['pos'].apply(lambda x:[i[0].upper().strip() for i in x])\n",
    "By_sentence_pos['Counter_pos']=By_sentence_pos['pos'].apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##計算總辭頻\n",
    "Counter_pos=By_sentence_pos[['Counter_pos']].copy()\n",
    "Counter_pos['group']=Counter_pos.index%2000\n",
    "group_Counter=Counter_pos.groupby('group')['Counter_pos'].sum()\n",
    "total_Counter=group_Counter.sum()\n",
    "ckip_pos=['VA','VB','VC','VD','VE','VH','VHC','VK','VJ','VL','VCL','Na','Nc','Nv']  #刪Nb\n",
    "total_word_counter={}\n",
    "for tuple_,count in total_Counter.most_common():\n",
    "    word,pos=tuple_\n",
    "    count_=0\n",
    "    word=word.upper().strip()\n",
    "    if count>1:\n",
    "        count_=total_word_counter.get(word,0)\n",
    "        if pos in ckip_pos:\n",
    "            count+=count_\n",
    "            total_word_counter[word]=count\n",
    "        elif word =='101':\n",
    "            count+=count_\n",
    "            total_word_counter[word]=count\n",
    "        elif pos=='FW':\n",
    "            if len(word)>=3:\n",
    "                count+=count_\n",
    "                total_word_counter[word]=count\n",
    "total_word_counter=Counter(total_word_counter)\n",
    "total_word_counter = {k : v for k,v in total_word_counter.items() if v >1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#原先分類字典(加入LDA主題的)\n",
    "classif = pd.read_excel('./feature_dict_lda.xlsx')\n",
    "classif.columns=['service','place','clean','cp','comfort','sleep','environment','food']\n",
    "classif=classif.to_dict()\n",
    "service_list=np.array(list(classif['service'].values()))\n",
    "classif['service']=service_list[service_list!='nan']\n",
    "place_list=np.array(list(classif['place'].values()))\n",
    "classif['place']=place_list[place_list!='nan']\n",
    "clean_list=np.array(list(classif['clean'].values()))\n",
    "classif['clean']=clean_list[clean_list!='nan']\n",
    "cp_list=np.array(list(classif['cp'].values()))\n",
    "classif['cp']=cp_list[cp_list!='nan']\n",
    "comfort_list=np.array(list(classif['comfort'].values()))\n",
    "classif['comfort']=comfort_list[comfort_list!='nan']\n",
    "sleep_list=np.array(list(classif['sleep'].values()))\n",
    "classif['sleep']=sleep_list[sleep_list!='nan']\n",
    "food_list=np.array(list(classif['food'].values()))\n",
    "classif['food']=food_list[food_list!='nan']\n",
    "environment_list=np.array(list(classif['environment'].values()))\n",
    "classif['environment']=environment_list[environment_list!='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "By_sentence_pos['token_ckip']=By_sentence_pos['pos'].apply(lambda x:[i[0].upper().strip() for i in x if i[0] in total_word_counter.keys()])\n",
    "cut_word_sample=By_sentence_pos[['token_ckip']].copy()\n",
    "word_list=list(total_word_counter.keys())\n",
    "cut_word_sample=cut_word_sample.reset_index(drop=True)\n",
    "cut_word_sample['Counter']=cut_word_sample['token_ckip'].apply(Counter)\n",
    "cut_word_sample=cut_word_sample[cut_word_sample.Counter!={}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##利用卡方分配進行分類\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "def find_category(classif,x):\n",
    "    dict_=defaultdict(list)\n",
    "    for cate in classif.keys():\n",
    "        count_=0\n",
    "        same=set(x.keys()).intersection(set(classif[cate]))\n",
    "        for sa in same:\n",
    "            count_+=x[sa]\n",
    "        dict_[count_].append(cate)\n",
    "    category=dict_[max(dict_.keys())]\n",
    "    if max(dict_.keys())==0:\n",
    "        category= 'None'\n",
    "    return(category)\n",
    "\n",
    "new_flag=True\n",
    "iteration=1\n",
    "P=30\n",
    "while( (new_flag==True)|(iteration>15)):\n",
    "    print(iteration,datetime.now())\n",
    "    C=cut_word_sample.shape[0]\n",
    "    cut_word_sample['category']=cut_word_sample['Counter'].apply(lambda x: find_category(classif,x))\n",
    "    for cate_ in classif.keys():\n",
    "        cut_word_sample[f'Is_{cate_}']=cut_word_sample['category'].apply(lambda x: True if cate_ in x else False)\n",
    "    output_list=[]\n",
    "    for word_ in word_list:\n",
    "        cut_word_sample['Is_Exist']=cut_word_sample['Counter'].apply(lambda x:True if word_ in x.keys() else False)\n",
    "        for cate_ in classif.keys():\n",
    "            topic_df=cut_word_sample[cut_word_sample[f'Is_{cate_}']]\n",
    "            C1=topic_df['Counter'].apply(lambda x:x[word_]).sum()\n",
    "            C2=total_word_counter[word_]-C1\n",
    "            C3=topic_df[topic_df.Is_Exist==False].shape[0]\n",
    "            C4=cut_word_sample[(cut_word_sample.Is_Exist==False)&(cut_word_sample.Is_service==False)].shape[0]\n",
    "            try:\n",
    "                Chi = (C*((C1*C4-C2*C3)**2))/((C1+C3)*(C2+C4)*(C1+C2)*(C3+C4))\n",
    "            except ZeroDivisionError:\n",
    "                Chi =0\n",
    "            output_list.append([word_,cate_,Chi])\n",
    "    total_num=pd.DataFrame(output_list,columns=['word','category','Chi'])\n",
    "    new_flag=False\n",
    "    for cate in classif.keys():\n",
    "        new_flag=False\n",
    "        keyword_list=list(classif[cate])\n",
    "        new_word=total_num[total_num.category==cate].sort_values('Chi',ascending=False)[:P].word.values\n",
    "        for new in new_word:\n",
    "            if new not in keyword_list:\n",
    "                keyword_list.append(new)\n",
    "                new_flag=True\n",
    "        classif[cate]=keyword_list\n",
    "    new_classif=pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in classif.items() ]))\n",
    "    new_classif.to_xlsx('./feature_8topic.xlsx',index=False)\n",
    "    iteration+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
