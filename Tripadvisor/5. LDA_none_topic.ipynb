{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os  \n",
    "import sys  \n",
    "from sklearn import feature_extraction  \n",
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "By_sentence_pos=pd.read_csv('By_sentence_pos.csv')\n",
    "By_sentence_pos['pos']=By_sentence_pos['pos'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##過濾掉特別磁性\n",
    "ckip_pos=['VA','VB','VC','VD','VE','VH','VHC','VK','VJ','VL','VCL','Na','Nb','Nc','Nd','Nv','FW']\n",
    "By_sentence_pos['token']=By_sentence_pos['pos'].apply(lambda x:[i[0] for i in x if (i[1] in ckip_pos)] )\n",
    "from collections import Counter\n",
    "By_sentence_pos['Counter']=By_sentence_pos['token'].apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classiff_ckip=pd.read_csv('classiff_ckip.csv')\n",
    "\n",
    "class_token=[]\n",
    "for i in classiff_ckip.values:\n",
    "    for k in i:\n",
    "        if k!='nan':\n",
    "            class_token.append(k)\n",
    "            \n",
    "classif=classiff_ckip.to_dict()\n",
    "service_list=np.array(list(classif['service'].values()))\n",
    "classif['service']=service_list[service_list!='nan']\n",
    "place_list=np.array(list(classif['place'].values()))\n",
    "classif['place']=place_list[place_list!='nan']\n",
    "clean_list=np.array(list(classif['clean'].values()))\n",
    "classif['clean']=clean_list[clean_list!='nan']\n",
    "cp_list=np.array(list(classif['cp'].values()))\n",
    "classif['cp']=cp_list[cp_list!='nan']\n",
    "comfort_list=np.array(list(classif['comfort'].values()))\n",
    "classif['comfort']=comfort_list[comfort_list!='nan']\n",
    "sleep_list=np.array(list(classif['sleep'].values()))\n",
    "classif['sleep']=sleep_list[sleep_list!='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_Category(x):\n",
    "    cate=[]\n",
    "    token_set=set(x)\n",
    "    for category in classif.keys():\n",
    "        cate_set=set(classif[category])\n",
    "        if cate_set&token_set!=set():\n",
    "            cate.append(category)\n",
    "    if cate==[]:\n",
    "        cate=None\n",
    "    return cate\n",
    "By_sentence_pos['category']=By_sentence_pos['token'].apply(find_Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topic=By_sentence_pos[By_sentence_pos.category.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topic['no_class_token']=no_topic['token'].apply(lambda x:[i for i in x if i not in class_token ])\n",
    "no_topic['none_Class']=no_topic['no_class_token'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章字詞矩陣，沒有加權 ****注意單辭被排除在外\n",
    "vectorizer = CountVectorizer(min_df = 1,ngram_range= (0,1))  \n",
    "count = vectorizer.fit_transform(no_topic['none_Class']) \n",
    "transformer=TfidfTransformer()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_top_words(model, feature_names, n_top_words,j):\n",
    "    #打印每个主题下权重较高的term\n",
    "    ans=[]\n",
    "    for i in range(j):\n",
    "        word= list([feature_names[k] for k in model.components_[i].argsort()[:-n_top_words - 1:-1]])        \n",
    "        pro=list(proba[i][k] for k in model.components_[i].argsort()[:-n_top_words - 1:-1])\n",
    "        ans.append([word,pro])\n",
    "    return(ans)\n",
    "\n",
    "    #打印主题-词语分布矩阵\n",
    "    #print (model.components_)\n",
    "tf_feature_names = vectorizer.get_feature_names()\n",
    "all_result=[]\n",
    "perplexity=[]\n",
    "n_top_words=50\n",
    "#tf_feature_names = vectorizer.get_feature_names()\n",
    "for j in range(3,11):\n",
    "    tstart = time.time()\n",
    "    print(j)\n",
    "    lda = LatentDirichletAllocation(j, \n",
    "                                max_iter=3000,                #看要不要改大一點\n",
    "                                learning_method='batch',n_jobs=10)\n",
    "    lda.fit(count) #tf即为Document_word Sparse Matrix \n",
    "    proba=lda.components_ / lda.components_.sum(axis=1)[:, np.newaxis]\n",
    "    result=list_top_words(lda, tf_feature_names, n_top_words,j)\n",
    "    perple=lda.perplexity(count)\n",
    "    all_result.append(result)\n",
    "    perplexity.append(perple)\n",
    "    tend = time.time()#計時結束\n",
    "    print (\"It cost %f sec\" % (tend - tstart))#會自動做近位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic存成excel\n",
    "writer = pd.ExcelWriter('LDA_newtopic.xlsx')#, engine='xlsxwriter')\n",
    "for num_ , result in enumerate(all_result):\n",
    "    topic_df=pd.DataFrame()\n",
    "    number=num_+2\n",
    "    for index_,topics in enumerate(result):\n",
    "        topic_df[f'topic_{index_}_word']=topics[0]\n",
    "        topic_df[f'topic_{index_}_prob']=topics[1]\n",
    "    topic_df.to_excel(writer,sheet_name=f'{number}_topic')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 繪圖-perplexity\n",
    "* 根據該結果找出合適主題數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def graph_draw(topic,perplexity):\n",
    "    x = topic\n",
    "    y = perplexity\n",
    "    plt.plot(x,y,color = 'red',linewidth=2)\n",
    "    plt.xlabel(' Number of Topic')\n",
    "    plt.ylabel('Perplexity')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = [2,3,4,5,6,7,8,9,10]\n",
    "graph_draw(topic,perplexity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
